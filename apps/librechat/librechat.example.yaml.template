version: 1.1.4
cache: true
interface:
  privacyPolicy:
    externalUrl: 'https://librechat.ai/privacy-policy'
    openNewTab: true

  termsOfService:
    externalUrl: 'https://librechat.ai/tos'
    openNewTab: true
endpoints:
  custom:
      - name: "Ollama"
        apiKey: "ollama"
        # Dynamic URL based on environment
        # Format: http://ollama[-environment].flycast/v1/
        baseURL: "http://ollama${ENVIRONMENT_SUFFIX}.flycast/v1/" 
        models:
          default: [
            "deepseek-r1:70b",
            "deepseek-r1:14b",
            "phi4:14b"
            ]
          fetch: false
        titleConvo: true
        titleModel: "current_model"
        summarize: false
        summaryModel: "current_model"
        forcePrompt: false
        modelDisplayLabel: "Ollama"
        addParams:
          "stop": [
            "<|im_start|>",
            "<|im_end|>",
            "<|im_sep|>",
            "<|begin_of_sentence|>",
            "<|end_of_sentence|>",
            "<|User|>",
            "<|Assistant|>",
          ]