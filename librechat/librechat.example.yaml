# For more information, see the Configuration Guide:
# https://docs.librechat.ai/install/configuration/custom_config.html

# Configuration version (required)
version: 1.0.6

# Cache settings: Set to true to enable caching
cache: true

# Custom interface configuration
interface:
  privacyPolicy:
    externalUrl: 'https://librechat.ai/privacy-policy'
    openNewTab: true

  termsOfService:
    externalUrl: 'https://librechat.ai/tos'
    openNewTab: true

# Definition of custom endpoints
endpoints:
  custom:
      - name: "Ollama"
        apiKey: "ollama"
        baseURL: "http://librechat-pg-ollama.internal:11434/v1/chat/completions" 
        models:
          default: [
            "llama3",
            ]
          fetch: false
        titleConvo: true
        titleModel: "current_model"
        summarize: false
        summaryModel: "current_model"
        forcePrompt: false
        modelDisplayLabel: "Ollama"
        addParams:
          "stop": [
            "<|start_header_id|>",
            "<|end_header_id|>",
            "<|eot_id|>",
            "<|reserved_special_token"
          ]